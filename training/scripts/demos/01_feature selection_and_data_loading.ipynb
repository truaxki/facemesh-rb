{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01_feature selection_and_data_loading\n",
    "\n",
    "This notebook demonstrates how to use the FacemeshDataLoader class with facial landmark clusters for targeted analysis.\n",
    "\n",
    "## Overview\n",
    "- **Data Loader**: Handles loading enhanced CSV files with rolling baseline features\n",
    "- **Facial Clusters**: Predefined anatomical groupings of landmarks for focused analysis\n",
    "- **Rolling Baseline Features**: Temporal features (rb5, rb10) that provide movement context\n",
    "\n",
    "## Configuration Options\n",
    "You can customize the data loading in several ways:\n",
    "- **Window Size**: Choose between 5-frame (rb5) or 10-frame (rb10) rolling baselines\n",
    "- **Feature Types**: Select 'base', 'rb', 'diff', or combinations\n",
    "- **Facial Regions**: Focus on specific anatomical areas (eyes, mouth, etc.)\n",
    "- **Subjects**: Choose which participants to include\n",
    "- **Sessions**: Select baseline, specific sessions, or all sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Imports successful\n",
      "Available facial clusters: 32\n",
      "Available cluster groups: 7\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# Direct imports (no path modification needed)\n",
    "from data_loader_template import FacemeshDataLoader\n",
    "from facial_clusters import (\n",
    "    FACIAL_CLUSTERS, CLUSTER_GROUPS, EXPRESSION_CLUSTERS,\n",
    "    get_cluster_indices, get_group_indices, \n",
    "    get_all_cluster_names, get_all_group_names\n",
    ")\n",
    "\n",
    "print(\"✓ Imports successful\")\n",
    "print(f\"Available facial clusters: {len(FACIAL_CLUSTERS)}\")\n",
    "print(f\"Available cluster groups: {len(CLUSTER_GROUPS)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = FacemeshDataLoader(window_size=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Facial Landmark Clusters\n",
    "\n",
    "MediaPipe provides 478 facial landmarks. We've organized these into anatomically meaningful clusters:\n",
    "\n",
    "### Individual Clusters\n",
    "- **Eyes**: Detailed upper/lower regions, iris tracking\n",
    "- **Mouth**: Inner/outer lip boundaries  \n",
    "- **Eyebrows**: Upper and lower eyebrow regions\n",
    "- **Nose**: Tip, bottom, corners\n",
    "- **Face Shape**: Silhouette/outline points\n",
    "\n",
    "### Grouped Regions\n",
    "- **mouth**: All lip-related clusters\n",
    "- **eyes**: Combined left/right eye regions\n",
    "- **eyebrows**: Combined eyebrow regions\n",
    "- **nose**: All nose-related points\n",
    "- **face_shape**: Overall face outline\n",
    "\n",
    "### Expression-Specific Clusters\n",
    "Predefined combinations for common expressions like smile, frown, surprise, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== INDIVIDUAL CLUSTERS ===\n",
      "leftCheek           :  1 landmarks\n",
      "leftEyeIris         :  5 landmarks\n",
      "leftEyeLower0       :  9 landmarks\n",
      "leftEyeLower1       :  9 landmarks\n",
      "leftEyeLower2       :  9 landmarks\n",
      "leftEyeLower3       :  9 landmarks\n",
      "leftEyeUpper0       :  7 landmarks\n",
      "leftEyeUpper1       :  7 landmarks\n",
      "leftEyeUpper2       :  7 landmarks\n",
      "leftEyebrowLower    :  6 landmarks\n",
      "leftEyebrowUpper    :  8 landmarks\n",
      "lipsLowerInner      : 11 landmarks\n",
      "lipsLowerOuter      : 10 landmarks\n",
      "lipsUpperInner      : 11 landmarks\n",
      "lipsUpperOuter      : 11 landmarks\n",
      "midwayBetweenEyes   :  1 landmarks\n",
      "noseBottom          :  1 landmarks\n",
      "noseLeftCorner      :  1 landmarks\n",
      "noseRightCorner     :  1 landmarks\n",
      "noseTip             :  1 landmarks\n",
      "rightCheek          :  1 landmarks\n",
      "rightEyeIris        :  5 landmarks\n",
      "rightEyeLower0      :  9 landmarks\n",
      "rightEyeLower1      :  9 landmarks\n",
      "rightEyeLower2      :  9 landmarks\n",
      "rightEyeLower3      :  9 landmarks\n",
      "rightEyeUpper0      :  7 landmarks\n",
      "rightEyeUpper1      :  7 landmarks\n",
      "rightEyeUpper2      :  7 landmarks\n",
      "rightEyebrowLower   :  6 landmarks\n",
      "rightEyebrowUpper   :  8 landmarks\n",
      "silhouette          : 36 landmarks\n",
      "\n",
      "=== CLUSTER GROUPS ===\n",
      "cheeks         :   2 landmarks\n",
      "eyebrows       :  28 landmarks\n",
      "face_shape     :  36 landmarks\n",
      "left_eye       :  62 landmarks\n",
      "mouth          :  40 landmarks\n",
      "nose           :   4 landmarks\n",
      "right_eye      :  62 landmarks\n",
      "\n",
      "=== EXPRESSION CLUSTERS ===\n",
      "smile          : ['mouth', 'cheeks'] (42 landmarks)\n",
      "frown          : ['mouth', 'eyebrows'] (68 landmarks)\n",
      "surprise       : ['mouth', 'eyebrows', 'eyes'] (68 landmarks)\n",
      "squint         : ['eyes', 'cheeks'] (2 landmarks)\n",
      "disgust        : ['nose', 'mouth'] (44 landmarks)\n",
      "concentration  : ['eyebrows', 'eyes'] (28 landmarks)\n"
     ]
    }
   ],
   "source": [
    "# Display available clusters and groups\n",
    "print(\"=== INDIVIDUAL CLUSTERS ===\")\n",
    "for cluster_name in sorted(get_all_cluster_names()):\n",
    "    indices = get_cluster_indices(cluster_name)\n",
    "    print(f\"{cluster_name:20}: {len(indices):2d} landmarks\")\n",
    "\n",
    "print(\"\\n=== CLUSTER GROUPS ===\")\n",
    "for group_name in sorted(get_all_group_names()):\n",
    "    indices = get_group_indices(group_name)\n",
    "    print(f\"{group_name:15}: {len(indices):3d} landmarks\")\n",
    "\n",
    "print(\"\\n=== EXPRESSION CLUSTERS ===\")\n",
    "for expr, groups in EXPRESSION_CLUSTERS.items():\n",
    "    total_landmarks = sum(len(get_group_indices(g)) for g in groups)\n",
    "    print(f\"{expr:15}: {groups} ({total_landmarks} landmarks)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loader Configuration\n",
    "\n",
    "The `FacemeshDataLoader` can be configured for different analysis needs:\n",
    "\n",
    "### Window Size Options:\n",
    "- **rb5**: 5-frame rolling baseline (captures short-term variations)\n",
    "- **rb10**: 10-frame rolling baseline (captures longer-term patterns)\n",
    "\n",
    "### Feature Type Options:\n",
    "- **'base'**: Original coordinate features (feat_X_y, feat_X_z)\n",
    "- **'rb'**: Rolling baseline averages (smoothed positions)\n",
    "- **'diff'**: Deviations from rolling baseline (movement intensity)\n",
    "\n",
    "### Typical Configurations:\n",
    "- **Movement Analysis**: Use 'diff' features to study motion patterns\n",
    "- **Position Analysis**: Use 'rb' features for stable positioning\n",
    "- **Full Analysis**: Use all feature types for comprehensive modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Data loader initialized\n",
      "  - Window size: 5 frames\n",
      "  - Data root: read\n",
      "  - Looking for files with suffix: -rb5\n"
     ]
    }
   ],
   "source": [
    "# Configuration options\n",
    "WINDOW_SIZE = 5  # or 10 for longer temporal context\n",
    "DATA_ROOT = \"read\"\n",
    "\n",
    "# Initialize data loader\n",
    "loader = FacemeshDataLoader(data_root=DATA_ROOT, window_size=WINDOW_SIZE)\n",
    "\n",
    "print(f\"✓ Data loader initialized\")\n",
    "print(f\"  - Window size: {WINDOW_SIZE} frames\")\n",
    "print(f\"  - Data root: {DATA_ROOT}\")\n",
    "print(f\"  - Looking for files with suffix: {loader.suffix}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Subject Data Loading\n",
    "\n",
    "Let's load data for one subject to understand the structure and verify everything works.\n",
    "\n",
    "### What we're testing:\n",
    "1. **File accessibility**: Can we find and load the enhanced CSV files?\n",
    "2. **Data structure**: What columns are available?\n",
    "3. **Feature organization**: How are the rolling baseline features organized?\n",
    "4. **Data quality**: Are there any obvious issues?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading e1-baseline...\n",
      "Warning: File not found - read\\e1\\e1-baseline-rb5.csv\n",
      "❌ Failed to load data for e1-baseline\n",
      "Check if the file exists and has the correct naming format\n"
     ]
    }
   ],
   "source": [
    "# Test loading single subject data\n",
    "TEST_SUBJECT = \"e1\"\n",
    "TEST_SESSION = \"baseline\"\n",
    "\n",
    "print(f\"Loading {TEST_SUBJECT}-{TEST_SESSION}...\")\n",
    "df_test = loader.load_subject_data(TEST_SUBJECT, TEST_SESSION)\n",
    "\n",
    "if not df_test.empty:\n",
    "    print(f\"✓ Successfully loaded data\")\n",
    "    print(f\"  - Rows: {len(df_test):,}\")\n",
    "    print(f\"  - Columns: {len(df_test.columns):,}\")\n",
    "    print(f\"  - Time range: {df_test['Time (s)'].min():.2f}s to {df_test['Time (s)'].max():.2f}s\")\n",
    "    print(f\"  - Duration: {df_test['Time (s)'].max() - df_test['Time (s)'].min():.2f}s\")\n",
    "    \n",
    "    # Show column types\n",
    "    feature_types = {\n",
    "        'metadata': [col for col in df_test.columns if col in ['Subject Name', 'Test Name', 'Time (s)', 'Face Depth (cm)']],\n",
    "        'base_features': [col for col in df_test.columns if col.startswith('feat_') and '_rb' not in col],\n",
    "        'rb_averages': [col for col in df_test.columns if f'_rb{WINDOW_SIZE}' in col and not col.endswith('_diff')],\n",
    "        'rb_differences': [col for col in df_test.columns if col.endswith(f'_rb{WINDOW_SIZE}_diff')]\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n=== COLUMN BREAKDOWN ===\")\n",
    "    for ftype, cols in feature_types.items():\n",
    "        print(f\"{ftype:15}: {len(cols):4d} columns\")\n",
    "        \n",
    "else:\n",
    "    print(f\"❌ Failed to load data for {TEST_SUBJECT}-{TEST_SESSION}\")\n",
    "    print(\"Check if the file exists and has the correct naming format\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
